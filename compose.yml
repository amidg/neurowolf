services:
  neurowolf:
    build:
      context: .
      dockerfile: Containerfile
    container_name: neurowolf
    environment:
      - LLM_MODEL=gemma3:4b
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - OLLAMA_HOST=${OLLAMA_HOST}
    tty: true
    stdin_open: true
    volumes:
      - ./:/app:ro
    restart: unless-stopped
